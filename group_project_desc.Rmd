---
title: "group_project_description"
output: html_document
author: "Chaya Maheshwari, Pedro Henriques, Jada Neumann, Stanislaw Ostoja-Starzewski"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Lending Club Loans

<B>Problem Statement:</B>

The project aims to segment Lending Club's customers base so that P2P investors are better able to understand their expected returns given their lenders characetrisitics. For that purpose we will use two variables: PD (Probability of Default) and LGD (Loss Given Default). We will then have a model that allows us to estimate expected returns for each investment.


<B>Process:</B>

1) Define Business Problem
- Lending Club allows people with weak financial knowledge to invest in what can be highly risky assets. Our goal is to provide potential investors with inteligence that allows them to make better investment decisions. For that purpose we analize 500k entries of past data past investment data to build a predictive model. Our key risk parameter will be the Probability of Default (PD), i.e. the probability of a lender not servicing his debt on time

2) Collect and clean up Data
- Step 1: download data from lendingclub.com or kaggle.com
- Step 2: test unique identifier for each entry/loan
- Step 3: eliminate variables that are out of scope or are too lengthy to parse/process for the benefit of analysis 
- Step 4: create dummy variables for non-numeric values
(...)

3) Dimentionality Reduction
- Step 1: analysing correlations and identifying variables which are linear combinations of one another
- Step 2: visualization (?)
- Step 3: create factors and decide which ones to keep based on a eigenvalue analysis
- Step 4: interpret the factors
- (...)

4) Clustering

5) Choose method to avoid overfitting

6) Build and test the model
- use 90% of the retained data entries to build the model
- use remaining 10% of data entries to test the model. Define the threshold values for test success.

